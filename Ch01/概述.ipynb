{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 什么是机器学习\n",
    "机器学习是一个研究领域，让计算机无需进行明确编程就具备学习能力\n",
    "更工程化的概念：一个计算机程序利用经验E来学习任务T，性能是P，如果针对任务T的性能P随着经验E的不断增长，则称为机器学习"
   ],
   "id": "9b982971cc3a27f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "例如,垃圾邮件过滤器就是一个机器学习程序,它可以根据垃圾\n",
    "邮件(比如,用户标记的垃圾邮件)和普通邮件(非垃圾邮件,也称\n",
    "作ham)学习标记垃圾邮件。系统用来进行学习的样例称作训练集。每\n",
    "个训练样例称作训练实例(或样本)。在这个示例中,任务T就是标记\n",
    "新邮件是否是垃圾邮件,经验E是训练数据,性能P需要定义。例如,\n",
    "可以使用正确分类邮件的比例。这个性能指标称为准确率,通常用在\n",
    "分类任务中。"
   ],
   "id": "7edea8f290698aaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](机器学习帮助人类学习.png)\n",
    "使用机器学习方法挖掘大量数据来帮助发现不太明显的规律，这称作数据挖掘\n"
   ],
   "id": "e27abcdcc1de166"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 机器学习系统的类型",
   "id": "c1094798d5021fb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 根据训练期间接受的监督数量和监督类型，可以将机器学习系统分为以下四个主要类别：监督学习，无监督学习\n",
    "#### 、半监督学习、自监督学习\n",
    "\n",
    "\n",
    "How they are supervised during training (supervised, unsupervised,semi-supervised, self-supervised, and others)\n",
    "\n",
    "#### 它们是通过简单地将新数据点与已知数据点进行比较，还是通过检测训练数据中的模式并构建预测模型（类似于科学家的方法）（基于实例的学习与基于模型的学习）。\n",
    "基于实例的学习（Instance-based Learning）：这种方法直接将新数据点与已知数据点进行比较。也就是说，当遇到新的数据时，系统会查找与其相似的已知数据点，然后根据这些相似数据点来做出预测。它并不试图总结出一个普遍的规则，而是依赖于已有数据点的相似性。这种方法类似于“记忆”已知的实例，并根据相似性来判断。\n",
    "\n",
    "基于模型的学习（Model-based Learning）：这种方法则更像科学家们的做法，它通过观察训练数据中的模式和规律，构建一个预测模型来解释这些模式。当有新的数据输入时，系统不再依赖于对具体实例的比较，而是根据训练出的模型来预测结果。这种方法试图总结出一般规律，用来解释和预测新的情况。\n",
    "\n",
    "\n",
    "---"
   ],
   "id": "a31530276b973c59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ">**训练监督（Training Supervision）** 指的是在机器学习训练过程中对模型进行指导的方式。根据监督的程度和数据标注情况，训练监督通常分为以下几种类型：\n",
    "\n",
    "> <span style=\"background-color:yellow\">监督学习</span>（Supervised Learning）：训练数据带有明确的标签，模型在学习过程中利用这些标签来逐渐调整和优化，以提高预测准确性。例如，在垃圾邮件分类中，系统会接收带有“垃圾邮件”或“非垃圾邮件”标签的邮件样本，从而学习如何区分两类邮件。\n",
    "\n",
    "><span style=\"background-color:yellow\">无监督学习</span>（Unsupervised Learning）：训练数据没有标签，模型通过分析数据内部的结构和模式来自行分类或聚类。例如，客户分群分析中，模型可以根据客户行为的相似性进行聚类，而不需要任何预定义的标签。\n",
    "\n",
    "><span style=\"background-color: yellow;\">半监督学习</span>（Semi-Supervised Learning）：训练数据中部分样本带有标签，部分没有标签。模型会利用有标签的数据指导训练，同时从无标签数据中获取额外的信息。这种方法适用于获取标签代价高的数据集。\n",
    "\n",
    "><mark>自监督学习</mark>（Self-Supervised Learning）：模型在没有人工标注的情况下，自行生成标签。例如，语言模型可以通过预测下一个单词来训练自己，这种方法在自然语言处理和图像处理等领域非常常见。\n",
    "\n",
    "强化学习（Reinforcement Learning）：模型在与环境交互的过程中，基于反馈（奖励或惩罚）来调整策略，从而找到最优的行为方式。比如机器人学习行走时，会根据每一步的成功或失败进行调整，以逐渐优化行走策略。"
   ],
   "id": "d73baf896d6cc1d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 监督学习\n",
    "\n",
    "在监督学习中，提供给算法的训练集包含所需的结果，称为<span style=\"background-color: yellow;\">**标签**</span> 如图1-5\n",
    "![](带有标签的训练集.png)"
   ],
   "id": "ae098896d394a69a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "一个典型的监督学习任务是分类。垃圾邮件过滤器就是一个很好的例子：它使用许多示例电子邮件以及它们的类别（垃圾邮件或火腿）进行训练，并且它必须学习如何对新电子邮件进行分类。\n",
    "\n",
    "另一个典型的任务是预测一个目标数值，比如给定一组特征（里程、车龄、品牌等），预测一辆车的价格。这类任务被称为回归（图1-6）\n",
    "![](回归模型.png)\n"
   ],
   "id": "602e9813cad73e1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Notice\n",
    "\n",
    "在监督学习中，“目标”和“标签”通常视为同义词，但在回归任务中更常用“目标”，而在分类任务中更常用“标签”。此外，“特征”有时也称为“预测变量”或“属性”。这些术语可以指单个样本（例如，“这辆车的里程特征为15,000”）或所有样本（例如，“里程特征与价格高度相关”）。"
   ],
   "id": "fca1a40304dfbcbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 无监督学习\n",
    "\n",
    "在无监督学习中，训练集是没有标签的，如图1-7，这个系统尝试去学习，没有指导的情况下。\n",
    "![](1-7.png)\n",
    "\n",
    "例如，假设您有大量关于博客访问者的数据。您可能想要运行一个聚类算法来尝试检测相似访问者组（图1-8）。在任何情况下，你都不需要告诉算法访问者属于哪个组：它会在没有你帮助的情况下找到这些连接。例如，它可能会注意到40%的访问者是喜欢漫画书的青少年，他们通常在放学后阅读你的博客，而20%的访问者是喜欢科幻小说的成年人，他们在周末访问你的博客。如果使用分层聚类算法，它还可以将每个组细分为更小的组。这可以帮助你针对每个群体发布你的帖子。\n",
    "![](1-8.png)\n",
    "可视化算法也是无监督学习的好例子：你向它们提供大量复杂和未标记的数据，它们输出2D或3D表示你的数据，可以很容易地绘制（图1-9）。这些算法试图尽可能多地保留结构（例如，试图在可视化中保持输入空间中的独立集群不重叠），以便您可以理解数据是如何组织的，并可能识别未预料到的模式。\n",
    "![](1-9.png)\n",
    "\n",
    "一个相关的任务是<span style=\"background-color: yellow;\">降维</span>，其目标是在不丢失太多信息的情况下简化数据。一种方法是将几个相关的特征合并为一个。例如，一辆汽车的行驶里程可能与它的车龄密切相关，因此降维算法将把它们合并为一个特征，代表汽车的磨损情况。这被称为<span style=\"background-color: yellow;\">特征提取</span>。\n",
    "\n",
    ">Tip\n",
    "> 在将训练数据提供给另一个机器学习算法（例如监督学习算法）之前，尝试使用降维算法减少训练数据中的维数通常是一个好主意。它将运行得更快，数据将占用更少的磁盘和内存空间，在某些情况下，它也可能表现得更好。\n"
   ],
   "id": "cf8cf1f103a41806"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 半监督学习\n",
    "\n",
    "由于标记数据通常既耗时又昂贵，因此通常会有大量未标记的实例和很少的标记实例。一些算法可以处理部分标记的数据。这被称为半监督学习（图1-11）。\n",
    "![](1-11.png)\n",
    "\n",
    "在半监督学习中，未标记的数据（在此图中为圆形）可以提供一些结构信息，帮助确定新实例（即十字形）的分类。尽管新实例离标记的方形类更近，但由于未标记的圆形数据的分布显示三角形类和方形类的不同区域，模型会将新实例归入与其分布更一致的三角形类。这意味着算法利用了数据的整体结构和分布模式，而不仅仅是单个样本的距离，从而得出更符合数据分布的分类结果。\n",
    "\n",
    "在半监督学习中，未标记的数据（在此图中为圆形）可以提供一些结构信息，帮助确定新实例（即十字形）的分类。尽管新实例离标记的方形类更近，但由于未标记的圆形数据的分布显示三角形类和方形类的不同区域，模型会将新实例归入与其分布更一致的三角形类。这意味着算法利用了数据的整体结构和分布模式，而不仅仅是单个样本的距离，从而得出更符合数据分布的分类结果。"
   ],
   "id": "af6ad65ee887fcbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 自监督学习\n",
    "> \n",
    "机器学习的另一种方法涉及从一个完全未标记的数据集生成一个完全标记的数据集。同样，一旦整个数据集被标记，任何监督学习算法都可以使用。这种方法被称为自监督学习。\n",
    "\n",
    "例如，如果你有一个大的未标记图像数据集，你可以随机屏蔽每个图像的一小部分，然后训练一个模型来恢复原始图像（图1-12）。\n",
    "![](1-12.png)\n",
    "在训练中，打马图像被当作模型的输入，原始图像当作标签。\n",
    "生成的模型本身可能非常有用，例如，修复损坏的图像或从图像中删除不需要的物体。但通常情况下，使用自我监督学习训练的模型并不是最终目标。您通常需要为稍微不同的任务（您真正关心的任务）调整和微调模型。\n",
    "\n",
    "例如，假设你真正想要的是一个宠物分类模型：给定任何宠物的图片，它将告诉你它属于哪个物种。如果你有一个大的未标记宠物照片数据集，你可以从使用自监督学习训练一个图像修复模型开始。一旦它表现良好，它应该能够区分不同的宠物种类：当它修复了一张脸被蒙住的猫的图像时，它必须知道不要添加狗的脸。假设你的模型架构允许（大多数神经网络架构都允许），那么就有可能调整模型，使其预测宠物物种，而不是修复图像。最后一步是在标记的数据集上对模型进行微调：模型已经知道猫、狗和其他宠物物种的样子，所以只需要这一步，模型就可以学习它已经知道的物种和我们期望从它那里得到的标签之间的映射。"
   ],
   "id": "fa7b35ef4fbbd605"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Note\n",
    "> \n",
    "将知识从一个任务转移到另一个任务被称为迁移学习，它是当今机器学习中最重要的技术之一，特别是在使用深度神经网络（即由多层神经元组成的神经网络）时。我们将在第二部分详细讨论这一点。"
   ],
   "id": "54449bf6c7f7a52b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "有些人认为自监督学习是无监督学习的一部分，因为它处理的是完全未标记的数据集。但是自监督学习在训练过程中使用（生成的）标签，所以在这方面它更接近监督学习。术语“无监督学习”通常用于处理聚类、降维或异常检测等任务，而自监督学习则关注与监督学习相同的任务：主要是分类和回归。简而言之，最好将自我监督学习作为一个单独的类别来对待。",
   "id": "24c1df327419948e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 强化学习\n",
    "> \n",
    "强化学习是一个非常不同的东西。在这种情况下，学习系统被称为agent，它可以观察环境，选择并执行动作，并获得奖励（或者以负奖励的形式进行惩罚，如图1-13所示）。然后它必须自己学习什么是最好的策略，称为策略，随着时间的推移获得最大的回报。策略定义了代理在给定情况下应该选择的操作。\n",
    "![](1-13.png)\n",
    "例如，许多机器人采用强化学习算法来学习如何走路。DeepMind的AlphaGo程序也是强化学习的一个很好的例子：2017年5月，它在围棋比赛中击败了当时世界排名第一的棋手柯洁，成为头条新闻。它通过分析数以百万计的游戏，然后与自己进行多次对弈，从而掌握了获胜策略。请注意，在与冠军的比赛中，学习被关闭了；AlphaGo只是在应用它学到的策略。正如您将在下一节中看到的，这被称为离线学习。"
   ],
   "id": "1d2ebb684506b7b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 批量学习与在线学习(增量学习)\n",
    "> \n",
    "在机器学习中，批量学习和在线学习是两种不同的数据处理方式，用于训练模型。\n",
    "\n",
    "批量学习（Batch Learning）：在批量学习中，模型一次性使用所有可用的训练数据进行训练。训练过程通常在离线环境中进行，因为需要较多的计算资源。训练完成后，模型被部署到生产环境中，处理新数据时不再进行学习，而是直接应用已训练好的模型。这种方法适用于数据变化缓慢的情况，模型可以定期用新的完整数据集重新训练，以保持准确性。然而，批量学习需要较长的训练时间和大量的计算资源，尤其在数据量庞大时。\n",
    "\n",
    "在线学习（Online Learning）：在线学习中，模型可以逐步学习到来的数据，而不是一次性使用所有数据。数据被逐个或按小批次（mini-batch）提供给模型，模型在每一步都进行快速更新。在线学习适用于数据持续更新的情况，能够实时适应新模式。此外，它还适用于内存有限或无法存储完整数据集的场景。例如，在金融市场预测中，模型需要快速适应新的市场动态。在线学习的关键参数是学习率，即模型适应新数据的速度。较高的学习率会让模型迅速适应新数据，但可能遗忘旧数据；较低的学习率则会让模型在新旧数据之间更平衡。\n",
    "\n",
    "如果你想让一个批处理学习系统了解新数据（比如一种新的垃圾邮件），你需要在完整的数据集（不仅是新数据，还有旧数据）上从头开始训练一个新版本的系统，然后用新模型替换旧模型。幸运的是，训练、评估和启动机器学习系统的整个过程可以相当容易地自动化（如图1-3所示），因此即使是批量学习系统也可以适应变化。只需根据需要更新数据并从头开始训练新版本的系统。\n",
    "\n",
    "\n",
    "在在线学习中，系统通过逐步提供数据实例来进行增量训练，可以是逐个提供，也可以按小组（称为小批量）提供。每一步学习的速度快且成本低，因此系统可以在数据到达时实时学习新数据（见图1-14）。\n",
    "![](1-14.png)\n",
    "此外，在线学习算法可用于在无法容纳一台机器主存储器的庞大数据集上训练模型（这称为核心外学习）。该算法加载部分数据，在该数据上运行训练步骤，并重复该过程，直到它在所有数据上运行（参见图1-15）。\n",
    "![](1-15.png)\n",
    "在线学习系统的一个重要参数是它们适应变化数据的速度，这称为学习率。如果设置较高的学习率，系统会快速适应新数据，但也容易很快遗忘旧数据（例如，您不希望垃圾邮件过滤器只识别最新的垃圾邮件类型）。相反，如果设置较低的学习率，系统将具有更大的惯性，即学习速度会变慢，但对新数据中的噪声或非代表性数据点（离群点）的敏感性也会降低\n",
    "\n",
    "> Note\n",
    "> \n",
    "在线学习中提到的学习率确实与损失函数中的超参数“学习率”相同。**学习率（learning rate**是机器学习和深度学习中的一个关键超参数，它控制模型在每次更新时步进的大小，从而决定模型适应新数据的速度。\n",
    "\n",
    "在损失函数优化过程中，学习率决定了梯度下降算法（或其他优化算法）每一步的移动幅度：\n",
    "\n",
    "较高的学习率使模型更快速地适应新数据，但容易导致模型遗忘旧数据（尤其是在在线学习中），并可能引发训练不稳定，导致模型在最优值附近来回波动或不收敛。\n",
    "\n",
    "较低的学习率使模型更新得更平缓，增加了模型稳定性，减小了对新数据噪声或异常值的敏感性，但也可能导致学习过程缓慢，甚至陷入局部最优而无法快速收敛。\n",
    "因此，设置合适的学习率在在线学习和批量学习中都非常重要，是平衡模型学习速度与稳定性的关键。\n",
    "\n",
    "数据质量和学习率)。如果它是一个运行的系统，你的客户会注意到的。例如，坏数据可能来自错误（例如，机器人上的故障传感器），也可能来自试图欺骗系统的人（例如，向搜索引擎发送垃圾邮件，试图在搜索结果中排名靠前）。为了减少这种风险，您需要密切监视系统，并在检测到性能下降时及时关闭学习（并可能恢复到以前的工作状态）。您可能还想监视输入数据并对异常数据作出反应；例如，使用异常检测算法（参见第9章）。"
   ],
   "id": "2ef76d5769cf25f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 基于模型的机器学习，与基于实例的机器学习\n",
    "> \n",
    "另一种对机器学习系统进行分类的方式是根据它们的泛化能力。大多数机器学习任务的目标是进行预测，这意味着在给定一定数量的训练示例的情况下，系统需要能够<span style=\"background-color: yellow;\">**对从未见过的示例进行良好的预测（即泛化 generalize）**</span>。在训练数据上的表现良好是好的，但还不够；真正的目标是能在新实例上表现出色。\n",
    "\n",
    "泛化主要有两种方法：基于实例的学习和基于模型的学习。\n",
    "\n",
    "基于实例的学习（Instance-Based Learning）：这种方法直接记住训练数据，当需要对新数据进行预测时，通过计算新数据与训练数据的相似性来做出决策。这种方法不试图总结数据中的模式，而是基于具体实例的相似性进行预测。\n",
    "\n",
    "基于模型的学习（Model-Based Learning）：这种方法通过训练数据中的模式来构建一个预测模型，并使用该模型对新数据进行预测。模型总结出一个适用于所有数据的规则，使其能够更好地在新实例上泛化。\n",
    "\n",
    "<span style=\"background-color: yellow;\">深度学习属于基于模型的学习</span>\n",
    "\n",
    "下面的例子为基于实例的学习\n",
    "\n",
    "最简单的学习形式可能就是简单地“记住”。如果你用这种方式创建一个垃圾邮件过滤器，它只会标记与用户已标记的垃圾邮件完全相同的邮件——虽然这不是最差的解决方案，但显然也不是最好的。\n",
    "\n",
    "与其仅仅标记那些与已知垃圾邮件完全相同的邮件，不如让过滤器能够标记那些与已知垃圾邮件非常相似的邮件。要实现这一点，就需要一种衡量两封邮件之间相似度的方法。一种（非常基础的）相似度衡量方法是计算两封邮件中共同词汇的数量。如果一封邮件与已知垃圾邮件有很多相同的词，那么系统就会将其标记为垃圾邮件。\n",
    "\n",
    "这被称为基于实例的学习：系统通过记住示例来学习，然后通过使用相似性度量将新案例与已学习的示例（或它们的子集）进行比较，从而对新案例进行泛化。例如，在图1-16中，新实例会被分类为三角形，因为与它最相似的实例中大多数都属于该类别。\n",
    "![](1-16.png)\n",
    "\n",
    "另一种从一组示例中进行泛化的方法是构建这些示例的模型，然后使用该模型进行预测。这被称为基于模型的学习（如图1-17所示）。\n",
    "![](1-17.png)\n"
   ],
   "id": "7ef50707859f1a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 一个典型的机器学习工作流程 a typical machine learning workflow\n",
    "> \n",
    ">1.模型选择\n",
    ">2.训练模型\n",
    "\n",
    "例子来自第三版P49\n",
    "例子1-1，使用Scikit-Learn训练与运行一个线性模型"
   ],
   "id": "664a304771858122"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T17:08:41.259223Z",
     "start_time": "2024-11-09T17:08:40.490494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Download and prepare the data\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values\n",
    "\n",
    "# Visualize the data\n",
    "lifesat.plot(kind='scatter',grid=True,\n",
    "             x='GDP per capita (USD)',y=\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()\n",
    "\n",
    "#select a linear model\n",
    "model = LinearRegression()\n",
    "\n",
    "#Train the model\n",
    "model.fit(X,y)\n",
    "\n",
    "#Make a predication for Cyprus\n",
    "X_new = [[37_655.2]]\n",
    "print(model.predict(X_new))\n"
   ],
   "id": "121f8391a2ca25bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.30165767]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In summary:\n",
    "1. You studied the data.\n",
    "2. You selected a model.\n",
    "3. You trained it on the training data (i.e., the learning algorithm searched\n",
    "for the model parameter values that minimize a cost function).\n",
    "4. Finally, you applied the model to make predictions on new cases (this\n",
    "is called inference), hoping that this model will generalize well.\n"
   ],
   "id": "6e4317e55b98b6f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Main Challenges of Machine Learning\n",
    "> 1. 非代表性训练数据 Nonrepresentative Training Data\n",
    "\n",
    "In order to generalize well,it is crucial that your training data be representative of the new cases you want to generalize to\n",
    "为了更好地泛化，你的训练数据必须能够代表你想要泛化的新案例。无论使用基于实例的学习还是基于模型的学习，都是如此。\n",
    "\n",
    "It is crucial to use a training set that is representative of the cases you want\n",
    "to generalize to. This is often harder than it sounds: if the sample is too\n",
    "small, you will have sampling noise (i.e., nonrepresentative data as a result\n",
    "of chance), but even very large samples can be nonrepresentative if the\n",
    "sampling method is flawed. This is called sampling bias.\n",
    "\n",
    "使用一个具有代表性的训练集来涵盖你希望泛化的情况是至关重要的。这通常比听起来要困难：如果样本过小，可能会出现采样噪声（即由于偶然因素导致的数据不具代表性），但即使是非常大的样本，如果采样方法存在缺陷，也可能导致样本不具代表性。这种现象被称为采样偏差(sampling bias)。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7bb8d36a1f2f4beb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ">2. 低质量数据 Poor-Quality Data\n",
    "\n",
    "显然，如果你的训练数据充满了错误、异常值和噪声（例如，由于测量质量差），系统将难以检测到潜在模式，从而可能导致性能下降。因此，花时间清理训练数据往往是非常值得的。事实上，大多数数据科学家都会花大量时间进行数据清理。以下是一些需要清理训练数据的示例：\n",
    "\n",
    "- 如果某些实例明显是异常值，那么简单地丢弃它们或尝试手动修复错误可能会有所帮助。\n",
    "- 如果某些实例缺少一些特征（例如，5%的客户未提供年龄），你需要决定是否要完全忽略该属性，忽略这些实例，用其他值（如年龄的中位数）填充缺失值，或者分别训练一个包含该特征的模型和一个不包含该特征的模型。\n",
    "\n",
    ">3. 无关特征 Irrelevant Feature\n",
    "\n",
    "\n",
    "只有当训练数据包含足够多的相关特征，并且无关特征较少时，系统才能有效学习。机器学习项目成功的关键部分是找到一组良好的特征来进行训练。这个过程称为特征工程，包括以下步骤：\n",
    "\n",
    "- Feature selection (selecting the most useful features to train on among\n",
    "existing features)\n",
    "\n",
    "- Feature extraction (combining existing features to produce a more\n",
    "useful one⁠—as we saw earlier, dimensionality reduction algorithms\n",
    "can help)\n",
    "\n",
    "- Creating new features by gathering new data\n",
    "- 特征选择：从现有特征中选择最有用的特征进行训练。\n",
    "- 特征提取：组合现有特征以生成更有用的特征——正如前面所提到的，降维算法可以帮助实现这一点。\n",
    "- 创建新特征：通过收集新数据来创建新的特征。"
   ],
   "id": "975b3b1e3545ce6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that we have looked at many examples of bad data, let’s look at a\n",
    "couple examples of bad algorithms.\n",
    "\n",
    ">1. Overfitting the training data  过拟合\n",
    " \n",
    "overfitting: it means that the model performs well on the training data,but it does not generalize well\n",
    "这意味着该模型在训练数据上表现良好，但泛化效果不佳。\n",
    "\n",
    "像深度神经网络这样的复杂模型可以检测数据中的微妙模式，但如果训练集噪声较多，或者样本过少导致采样噪声，那么模型很可能会在噪声中检测出模式（就像出租车司机的例子中那样）。显然，这些模式无法泛化到新的实例。例如，假设你为生活满意度模型提供了更多的属性，包括无用的信息，比如国家名称。在这种情况下，复杂模型可能会检测出一种模式，即训练数据中所有名称中带有“w”的国家的生活满意度都高于7：新西兰（7.3）、挪威（7.6）、瑞典（7.3）和瑞士（7.5）。你能多大程度上确信这种“w-满意度”规则适用于卢旺达或津巴布韦呢？显然，这种模式在训练数据中纯属偶然，但模型无法判断这个模式是真实的，还是仅仅是数据噪声的结果。\n",
    "\n",
    "过拟合发生在模型相对于训练数据的数量和噪声来说过于复杂的情况下。以下是一些可能的解决方案：\n",
    "\n",
    "- 通过选择参数较少的模型来简化模型（例如，选择线性模型而不是高次多项式模型），通过减少训练数据中的特征数量，或通过对模型进行约束。\n",
    "- 收集更多的训练数据。\n",
    "- 减少训练数据中的噪声（例如，修正数据错误并去除异常值）。\n",
    "\n",
    "Constraining a model to make it simpler and reduce the risk of overfitting is called **regularization.**\n",
    "\n",
    "通过对模型进行约束使其更简单，以降低过拟合风险，这被称为<span style=\"background-color: yellow;\">**正则化**</span>。\n",
    "\n",
    "例如，我们之前定义的线性模型有两个参数，θ₀ 和 θ₁，这为学习算法提供了两个自由度，使其可以调整模型以适应训练数据：它可以同时调整线的高度（θ₀）和斜率（θ₁）。如果我们强制 θ₁ = 0，算法将只有一个自由度，使得模型更难正确拟合数据：它只能上下移动直线，以尽可能接近训练实例，最终可能会接近数据的均值。这确实是一个非常简单的模型！如果我们允许算法修改 θ₁，但限制其值较小，那么学习算法的自由度将在一到二之间。这样生成的模型会比具有两个自由度的模型更简单，但比只有一个自由度的模型更复杂。目标是在完美拟合训练数据和保持模型简单之间找到一个适当的平衡，以确保模型能够很好地泛化到新数据上。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4272891cc8d007d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "图1-24展示了三个模型。虚线表示的是在仅包含圆形表示的国家（不包括方形国家）上训练的原始模型；实线是使用所有国家（圆形和方形）训练的第二个模型；而虚线则是一个使用与第一个模型相同的数据但加上正则化约束训练的模型。可以看到，正则化使模型的斜率更小：尽管这个模型对训练数据（圆形）拟合得不如第一个模型，但它对训练中未见过的新示例（方形）泛化得更好。\n",
    "![](1-24.png)\n",
    "\n",
    "\n",
    "<span style=\"background-color: yellow;\">在学习过程中应用的正则化量可以通过一个超参数来控制</span>。超参数是学习算法的参数（而不是模型的参数），因此它不受学习算法本身的影响，必须在训练之前设置，并在整个训练过程中保持不变。如果将正则化超参数设置为一个非常大的值，那么得到的模型会几乎是平的（斜率接近零）；这种情况下，学习算法几乎肯定不会过拟合训练数据，但也更难找到一个好的解决方案。调整超参数是构建机器学习系统的重要部分（在下一章中你会看到一个详细的示例）。\n",
    "\n",
    "\n",
    ">2. Underfitting the Training Data  欠拟合\n",
    "\n",
    "正如您可能猜到的那样，欠拟合与过拟合相反：当您的模型过于简单而无法学习数据的底层结构时，就会发生欠拟合。例如，生活满意度的线性模型容易欠拟合；现实比模型更复杂，所以它的预测必然是不准确的，即使是在训练样本上。\n",
    "\n",
    "Here are the main options for fixing this problem:\n",
    "- Select a more powerful model, with more parameters.\n",
    "- Feed better features to the learning algorithm (feature engineering).\n",
    "- Reduce the constraints on the model (for example by reducing the regularization hyperparameter).\n",
    "\n",
    "\n",
    "> 总结\n",
    "> \n",
    ">机器学习的核心在于通过数据学习，使机器在某些任务上不断优化，而无需显式编写规则。\n",
    "\n",
    ">机器学习系统有多种类型：可以是有监督或无监督的，可以是批量学习或在线学习，也可以是基于实例或基于模型的。\n",
    "\n",
    ">在机器学习项目中，你需要收集数据并构建训练集，然后将训练集输入到学习算法中。如果算法是基于模型的，它会调整一些参数来使模型适应训练集（即在训练集上做出良好的预测），并希望它在新的数据上也能做出准确的预测。如果算法是基于实例的，它只是记住示例，并通过相似度度量将新实例与已学示例进行比较，从而泛化到新数据。\n",
    "\n",
    ">如果训练集过小，或数据不具代表性、噪声过多，或者包含无关特征（即“垃圾进，垃圾出”），系统的表现将不佳。最后，模型既不能过于简单（否则会欠拟合），也不能过于复杂（否则会过拟合）。"
   ],
   "id": "8450c7fc7c160073"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Testing and Validating   测试和验证\n",
    "> \n",
    "\n",
    "The only way to know how well a model will generalize to new cases is to\n",
    "actually try it out on new cases. \n",
    "\n",
    "A better option is to split your data into two sets: the training set and the\n",
    "test set. As these names imply, you train your model using the training set,\n",
    "and you test it using the test set. The error rate on new cases is called the\n",
    "**generalization error** (or out-of-sample error), and by evaluating your model\n",
    "on the test set, you get an estimate of this error. This value tells you how\n",
    "well your model will perform on instances it has never seen before.\n",
    "If the training error is low (i.e., your model makes few mistakes on the\n",
    "training set) but the generalization error is high, it means that your model is\n",
    "overfitting the training data.\n",
    "\n",
    "判断模型能否很好地泛化到新实例的唯一方法是实际在新实例上进行测试。一种方法是将模型投入生产并监测其表现，这在某些情况下有效，但如果模型表现非常糟糕，用户可能会抱怨——显然这不是最佳方案。\n",
    "\n",
    "更好的方法是将数据分成两个集合：训练集和测试集。顾名思义，训练集用于训练模型，而测试集用于测试模型。模型在新实例上的错误率称为<span style=\"background-color:yellow\">**泛化误差**（或样本外误差）</span>，通过在测试集上评估模型，可以估算这一误差，从而了解模型在未见过的数据上的表现。\n",
    "\n",
    "如果训练误差较低（即模型在训练集上错误较少），但泛化误差较高，这表明模型对训练数据过拟合了。"
   ],
   "id": "6ec8c4aa64e96a72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Hyperparameter Tuning and Model Selection 超参数调优和模型选择\n",
    "> \n",
    "评估一个模型很简单：只需使用测试集即可。但假设你在两个模型之间犹豫不决（例如，线性模型和多项式模型），该如何选择？一种选择是训练两个模型并比较它们在测试集上的泛化效果。\n",
    "\n",
    "现在假设线性模型的泛化效果更好，但你想通过正则化来避免过拟合。那么问题来了，如何选择正则化超参数的值呢？一种方法是使用100个不同的超参数值训练100个不同的模型。假设你找到了一个最佳超参数值，使模型的泛化误差最低，比如仅5%。你将此模型投入生产，但不幸的是，模型的实际错误率达到了15%。这是怎么回事？\n",
    "\n",
    "问题在于，你在测试集上多次测量了泛化误差，并且调整了模型和超参数，以获得对该特定测试集效果最好的模型。这意味着模型在新数据上可能表现不佳。\n",
    "\n",
    "解决这一问题的一种常见方法称为<span style=\"background-color:yellow\">保留验证(holdout validation)</span>（见图1-25）：你可以将训练集的一部分留出，用来评估多个候选模型并选择最佳模型。这个新的保留集称为验证集(validation set)（或开发集，dev set）(development set)。具体而言，你可以在缩小后的训练集上（即完整的训练集减去验证集）训练多个具有不同超参数的模型，选择在验证集上表现最好的模型。经过这一保留验证过程后，将最佳模型在完整训练集（包括验证集）上进行训练，得到最终模型。最后，在测试集上评估该最终模型，以获得泛化误差的估计值。\n",
    "![](1-25.png)\n",
    "这种解决方案通常效果不错。然而，如果验证集太小，模型的评估将不够精确，可能会错误地选择一个次优的模型。相反，如果验证集太大，那么剩余的训练集将比完整训练集小得多。这有什么不好呢？因为最终模型会在完整的训练集上进行训练，因此在一个较小的训练集上训练候选模型并进行比较并不理想，就像挑选一名短跑选手去参加马拉松比赛一样。\n",
    "\n",
    "解决此问题的一种方法是进行<span style=\"background-color:yellow\">重复交叉验证</span>，使用多个小的验证集。每个模型在其余数据上训练后，会在每个验证集上评估一次。通过对所有评估结果取平均值，可以更准确地衡量模型的性能。然而，这种方法的缺点是训练时间会随着验证集的数量成倍增加。"
   ],
   "id": "67c3cd6481e2cd66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Data Mismatch 数据不匹配\n",
    "> \n",
    " 在某些情况下，获取大量训练数据并不困难，但这些数据可能无法完全代表生产环境中的实际数据。例如，假设你想创建一个可以拍摄花朵并自动识别其物种的移动应用程序。你可以轻松地从网络上下载数百万张花朵图片，但它们并不能完全代表用户通过移动设备实际拍摄的图片。也许你只有1000张真正具有代表性的图片（即实际使用该应用拍摄的图片）。<span style=\"background-style:yellow\">在这种情况下，最重要的原则是验证集和测试集必须尽可能代表你预计在生产中使用的数据</span>，因此它们应仅包含具有代表性的图片：可以将这些图片打乱，一半放入验证集，另一半放入测试集（确保两者中没有重复或几乎相同的图片）。\n",
    "\n",
    "如果在网络图片上训练模型后发现模型在验证集上的表现不佳，那么你将无法确定这是因为模型过拟合了训练集，还是仅仅由于网络图片与移动应用图片之间的差异造成的。\n",
    "\n",
    "一种解决方案是将部分训练图片（来自网络）放入另一个集合，称为训练开发集（train-dev set）（图1-26）。模型在训练集上训练完成后（不包括训练开发集），可以在训练开发集上评估模型。如果模型表现不佳，则说明它对训练集过拟合，应该尝试简化或正则化模型，获取更多训练数据，或清理训练数据。\n",
    "\n",
    "但如果模型在训练开发集上的表现良好，则可以继续在开发集（dev set）上评估模型。如果在开发集上表现不佳，那么问题可能出在数据不匹配上。可以尝试通过预处理网络图片，使其更接近移动应用拍摄的图片，然后重新训练模型。一旦模型在训练开发集和开发集上都表现良好，就可以在测试集上进行最后一次评估，以了解其在实际生产中的表现预期。\n",
    "![](1-26.png)\n",
    "图片下的译文：当真实数据稀缺（右）时，您可以使用类似的丰富数据（左）进行训练，并将其中一些数据放在训练开发集中以评估过拟合；然后使用真实数据来评估数据不匹配（开发集）和评估最终模型的性能（测试集）。"
   ],
   "id": "a2967475e1c22fb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Note No Free Lunch Theorem \n",
    "\n",
    "A model is a simplified representation of the data. The simplifications are meant to discard the superfluous details that are unlikely to generalize to new instances. When you select a particular type of model, you are implicitly making assumptions about the data. For example, if you choose a linear model, you are implicitly assuming that the data is fundamentally linear and that the distance between the instances and the straight line is just noise, which can safely be ignored. In a famous 1996 paper,⁠ David Wolpert demonstrated that if you make absolutely no assumption about the data, then there is no reason to prefer one model over any other. This is called the No Free Lunch (NFL) theorem. For some datasets the best model is a linear model, while for other datasets it is a neural network. There is no model that is a priori guaranteed to work better (hence the name of the theorem). The only way to know for sure which model is best is to evaluate them all. Since this is not possible, in practice you make some reasonable assumptions about the data and evaluate only a few reasonable models. For example, for simple tasks you may evaluate linear models with various levels of regularization, and for a complex problem you may evaluate various neural networks.\n",
    "\n",
    "模型的简化作用：\n",
    "\n",
    "模型是对数据的简化表示。我们在构建模型时，通常会忽略一些细节，以便让模型更易于理解和计算。这些细节有时被认为是“噪声”，可能不会对预测产生重要影响。\n",
    "选择模型时的隐含假设：\n",
    "\n",
    "每种模型都有自己的假设。例如，线性模型假设数据之间的关系是线性的（即可以用直线来表示）。换句话说，线性模型假设数据的变化可以通过一条直线来描述，偏离这条直线的差异仅仅是噪声，可以忽略掉。\n",
    "选择模型时，我们会基于对数据的假设来做决定。如果我们选择线性模型，我们就在假设数据是“线性”的。\n",
    "无免费午餐定理（NFL定理）：\n",
    "\n",
    "1996年，David Wolpert提出了无免费午餐定理，意思是：如果你对数据完全没有任何假设，那么没有任何模型会比其他模型更好。\n",
    "换句话说，对于所有可能的数据集，没有一个模型能在所有情况下都表现最优。例如，有些数据集用线性模型效果很好，而有些则需要使用复杂的神经网络才能得到良好的结果。没有哪个模型能在所有问题上都“稳赢”，因此我们不能简单地认为某种模型在所有场景下都会是最佳选择。\n",
    "实践中的做法：\n",
    "\n",
    "由于无法对所有模型进行全面评估（这会非常耗时和资源），我们通常会做出一些合理的假设来选择评估的模型。例如，对于简单任务，我们可能会选择不同正则化程度的线性模型进行评估；而对于复杂问题，则可能会选择各种不同结构的神经网络模型进行评估。\n",
    "核心在于实践中我们会选择有限的几个模型，并基于对数据的假设来评估它们，而不是尝试每一个模型。\n",
    "总结： 无免费午餐定理告诉我们，不能单纯地认为某个模型在所有场景下都能最优。实际中，我们会基于对数据的理解和假设，选择几个合适的模型进行评估，而不是一开始就试图穷举所有可能的模型。"
   ],
   "id": "47fe08996fded67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
